---
title: "COVID-19 in Newfoundland and Labrador"
subtitle: "Analysis and Modelling"
author: "John W"
date: "1-17-2025"
output:
  html_document:
    df_print: paged
---

# Introduction

This [RStudio](https://global.rstudio.com/categories/rstudio-ide/) notebook studies a number of data sets published by **Health Canada** on COVID-19 cases, vaccinations and variants. They will be used in this case to study the progression of the disease in Newfoundland and Labrador.

# What are the most common strains of COVID-19 currently circulating within the province?

To answer this question, we can make use of a data set which tracks the proportion of variants of COVID-19 in the province. It is updated weekly as of writing this notebook.

```{r}
library(tidyverse)
library(janitor)
library(viridis)

# Read the data
variants_df <- read_csv("https://health-infobase.canada.ca/src/data/covidLive/covid19-epiSummary-variants.csv")

# Clean the data and calculate days and proportions
variants_df <- variants_df %>%
  janitor::clean_names() %>%
  mutate(days = as.integer(as.Date(week_of_collection, format = "%Y-%m-%d") - min(as.Date(week_of_collection, format = "%Y-%m-%d")))) %>%
  mutate(variant = as.factor(variant)) %>%
  # Calculate proportions and median proportions for each variant
  group_by(variant) %>%
  mutate(proportions = proportions / 100) %>%
  mutate(median_proportion = median(proportions, na.rm = TRUE)) %>%
  ungroup()

# Reorder 'variant' based on median_proportion in descending order
variants_df$variant <- factor(variants_df$variant, levels = variants_df %>% 
                      group_by(variant) %>% 
                      summarise(median = median(median_proportion, na.rm = TRUE)) %>% 
                      arrange(desc(median)) %>% 
                      pull(variant))

# Plotting the boxplots sorted by median proportions
ggplot(variants_df, aes(x = variant, y = proportions, group = variant, color = variant)) +
  geom_boxplot() + 
  labs(
    title = "Proportion of Different COVID-19 Variants Over Time",
    subtitle = glue::glue("Newfoundland and Labrador (Last Updated on {max(variants_df$week_of_collection)})"),
    x = "COVID-19 Variant",
    y = "Proportion of Variants",
    fill = "COVID-19 Variant"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  ) +
  scale_color_viridis_d() +
  scale_y_continuous(labels = scales::percent)

```

There are at least 13 known strains of COVID-19 circulating in the province. The most common strain of the disease currently circulating is on the left, the rest have been arranged in descending order according to their median proportion. Outliers indicate sudden surges or other anomalies in case numbers for a given strain. The KP.3.1.1 strain has seen the greatest variation in its case numbers, at one point accounting for between 20% and 50% of the total cases.

# Which vaccines are most commonly administered in the province?

```{r}
vaccine_df <- read.csv("https://health-infobase.canada.ca/src/data/covidLive/vaccination-administration-bydosenumber_grouped.csv")

# Boxplot for vaccine groups ordered by maximum value with wrapped x labels
vaccine_df %>%
  janitor::clean_names() %>%
  filter(prename == "Newfoundland and Labrador") %>%
  filter(vaccine_group != "Total"  & vaccine_group != "Unknown") |>
  mutate(
    vaccine_group = factor(vaccine_group, 
                           levels = vaccine_df %>%
                             filter(prename == "Newfoundland and Labrador") %>%
                             group_by(vaccine_group) %>%
                             summarise(max_doses = max(numtotal_totaldoses_admin, na.rm = TRUE)) %>%
                             arrange(desc(max_doses)) %>%
                             pull(vaccine_group)),
    wrapped_vaccine_group = str_wrap(vaccine_group, width = 50)  # Wrap the text for x labels
  ) %>%
  ggplot(aes(x = wrapped_vaccine_group, y = numtotal_totaldoses_admin, color = vaccine_group)) +
  geom_boxplot() +
  labs(
    title = str_wrap("Total Doses Administered by Vaccine Group", width = 50),
    subtitle = glue::glue("Newfoundland and Labrador (Last Updated on {max(variants_df$week_of_collection)})"),
    x = "Vaccine Group",
    y = "Total Doses Administered"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),  # Adjusting angle for right-side up labels
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust=0.5),
  ) +
  scale_fill_viridis_d() +
  scale_y_continuous(labels = scales::number) +
  scale_color_viridis_d()




```

The Pfizer-BioNTech Comirnaty vaccines (with the original strain) have been administered in the province in the largest numbers.

# Random Forest Model

To study the progression of COVID-19 in the province, we will make use of the **random forest model.** The random forest model is an "ensemble machine learning algorithm that combines multiple decision trees to improve the accuracy, robustness, and generalization of predictions. It is widely used for both regression and classification tasks and is particularly effective for handling large, complex datasets with a variety of input features."<sup>1</sup>

## Plots

```{r}
# Load necessary libraries
library(tidyverse)
library(caret)
library(randomForest)
library(ggthemes)
library(RColorBrewer)
library(glue)  # For formatting the subtitle text
library(stringr)  # For text wrapping

# Load and prepare the data
data <- read.csv("https://health-infobase.canada.ca/src/data/covidLive/covid19-download.csv")

df <- data %>%
  filter(prname == "Newfoundland and Labrador") %>%
  mutate(
    totalcases = as.numeric(totalcases), 
    days = as.integer(as.Date(date, format = "%Y-%m-%d") - min(as.Date(date, format = "%Y-%m-%d"))),  # Calculate days since the first case
    sqrt_totalcases = sqrt(totalcases)  # Square root transformation of the totalcases
  ) %>%
  drop_na(sqrt_totalcases) %>% # Drop NA values for the transformed variable
  filter(!is.na(totalcases) & !is.infinite(totalcases)) %>%
  filter(totalcases > 0)

# Prepare feature matrix (X) and target variable (y)
X <- df %>%
  select(days) %>%
  as.matrix()

y <- df$sqrt_totalcases  # Target variable

# Convert X and y to numeric matrix and vector, respectively
X <- as.matrix(X)  # Ensure X is a matrix
y <- as.numeric(y)  # Ensure y is a numeric vector

# Split the data into training and test sets
set.seed(123)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, , drop = FALSE]  # Ensure X_train is a matrix
y_train <- y[train_index]
X_test <- X[-train_index, , drop = FALSE]  # Ensure X_test is a matrix
y_test <- y[-train_index]

# Convert to data frame for randomForest training
train_df <- data.frame(days = X_train, sqrt_totalcases = y_train)
test_df <- data.frame(days = X_test, sqrt_totalcases = y_test)

# Train the Random Forest model using caret
rf_model <- randomForest(sqrt_totalcases ~ days, data = train_df, ntree = 100, mtry = 1, importance = TRUE)

# Print model summary
print(rf_model)

# Make predictions on the test set
y_pred <- predict(rf_model, newdata = test_df)

# Evaluate the model on the test set
rmse <- sqrt(mean((y_test - y_pred)^2))
mae <- mean(abs(y_test - y_pred))
r2 <- 1 - sum((y_test - y_pred)^2) / sum((y_test - mean(y_test))^2)

# Print evaluation metrics
cat("Test RMSE:", rmse, "\n")
cat("Test MAE:", mae, "\n")
cat("Test R²:", r2, "\n")

# Cross-validation with caret
cv_model <- train(
  sqrt_totalcases ~ days, 
  data = train_df, 
  method = "rf", 
  trControl = trainControl(method = "cv", number = 5),  # 5-fold cross-validation
  tuneGrid = expand.grid(mtry = 1),  # Adjust this grid for hyperparameter tuning
  ntree = 100
)

# Cross-validation evaluation metrics
cv_rmse <- min(cv_model$resample$RMSE)
cv_mae <- min(cv_model$resample$MAE)
cv_r2 <- max(cv_model$resample$Rsquared)

# Create the subtitle with performance metrics
subtitle_text <- glue(
  "Test RMSE: {round(rmse, 2)} | Test MAE: {round(mae, 2)} | Test R²: {round(r2, 2)} | ",
  "CV RMSE: {round(cv_rmse, 2)} | CV MAE: {round(cv_mae, 2)} | CV R²: {round(cv_r2, 2)}"
)

# Wrap the subtitle text to fit within the plot using str_wrap
wrapped_subtitle <- str_wrap(subtitle_text, width = 80)

# Fitted curve for the existing data
# Generate predictions for the training and test sets
train_pred <- predict(rf_model, newdata = train_df)
test_pred <- predict(rf_model, newdata = test_df)

# Generate future predictions (for the next 365 days)
future_days <- data.frame(days = seq(max(df$days) + 1, max(df$days) + 365, by = 1))  # Next 365 days
future_pred <- predict(rf_model, newdata = future_days)

# Plot 1: Random Forest Predictions vs Actual Values as ggplot
ggplot() +
  geom_point(aes(x = y_test, y = y_pred), color = "blue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Random Forest Predictions vs Actual Values",
       x = "Actual", y = "Predicted",
       subtitle = wrapped_subtitle) +
  theme_minimal()

# Plot 2: Learning Curves (Training and Test RMSE)
learning_curve_data <- data.frame(
  ntree = rep(seq(50, 100, by = 50), 2),
  rmse = c(train_rmse, test_rmse),
  dataset = rep(c("Training", "Test"), each = length(seq(50, 100, by = 50)))
)

ggplot(learning_curve_data, aes(x = ntree, y = rmse, color = dataset)) +
  geom_line() +
  geom_point() +
  labs(title = "Learning Curves for Random Forest",
       x = "Number of Trees (ntree)",
       y = "Root Mean Squared Error (RMSE)",
       subtitle = "Training vs. Test Performance for Different Numbers of Trees") +
  theme_minimal() +
  scale_color_manual(values = c("blue", "red")) +
  theme(legend.title = element_blank())

# Plot 3: Fitted Curve for Full Data with Future Predictions using ggplot
full_data <- data.frame(days = df$days, sqrt_totalcases = df$sqrt_totalcases)
full_data$predictions <- predict(rf_model, newdata = full_data)

future_data <- data.frame(days = seq(max(df$days) + 1, max(df$days) + 365, by = 1))
future_data$predictions <- future_pred

ggplot() +
  geom_point(data = full_data, aes(x = days, y = sqrt_totalcases), color = "black") +
  geom_line(data = full_data, aes(x = days, y = predictions), color = "green", size = 1) +
  geom_line(data = future_data, aes(x = days, y = predictions), color = "blue", size = 1, linetype = "dashed") +
  labs(
    title = "Fitted Curve for Full Data and Future Predictions",
    x = "Days", y = "Sqrt(Total Cases)",
    subtitle = "Fitted Curve for Full Data with Predictions for the Next 365 Days"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("black", "green", "blue"))

```


The learning curves plot "is a graphical representation that shows how a machine learning model's performance improves as it is trained on more data or with different model configurations (such as the number of trees in a [random forest], or the number of training iterations in other models)."<sup>1</sup> It is useful in diagnosing issues with a model such as overfitting and underfitting, as well as for evaluating the model's ability to generalize. A residuals plot would typically be examined for this purpose, but in the case of the random forest model, a residuals plot is less useful in evaluating the model's performance. This stems from the fact that the random forest model is non-linear; it captures "complex relationships between the input features and the target variable by aggregating predictions from multiple decision trees."<sup>1</sup> A residuals plot assumes a linear relationship between the predicted values and the residuals, so in the case of models like random forest which do not assume linearity, they may not provide insight into the performance of such models.

# Conclusion

We have provided a general picture of the number of cases of different variants of COVID-19 in Newfoundland and Labrador, Canada. We have also examined the number and commercial name of vaccines distributed in the province. Finally, we have evaluated the effectiveness of the random forest model in its ability to describe and predict the progression of the disease in the province. The random forest model provides an excellent basis on which this progression can be described and predicted. Its strengths in modelling outbreaks of the disease may be summarized as follows:

- COVID-19 data often exhibits complex, non-linear relationships between variables. The random forest model is able to handle this complexity through its use of a collection of decision trees.

- COVID-19 data is often large and complex in its own right, particularly when factors like geography, testing rates and vaccination are taken into consideration. The random forest model is particularly well suited to such data sets, as it "can handle high-dimensional data with many predictors and complex interactions."<sup>1</sup>

- Random forest makes use of multiple decision trees using different subsets of the data, averaging their predictions. This helps to generalize the model and avoid the problem of overfitting.

- Random forest has a built-in method for evaluating feature importance. This is critical in the analysis of COVID-19, as it allows for one to identify which variables (e.g. government interventions, vaccinations) are most important in predicting the outcomes (in this case, total case count).

- COVID-19 data is often less than ideal in form, containing missing values due to incomplete reporting or other factors. Random forest is, by nature, less sensitive to this issue. It makes use of "surrogate splits in decision trees when data for a particular feature is unavailable."<sup>1</sup>

- Random forest is capable of handling both continuous and categorical variables. This is useful as COVID-19 data can often contain a variety of features, both categorical and continuous. Random forest can handle both of these types without any additional pre-processing.

- Random forest is particularly good at making predictions based on historical data. It can make future predictions based on such data, critical for intervention and planning strategies. In addition, it is capable of capturing the sudden shift in trends that can often occur in an outbreak of the disease (e.g. the arrival of a new variant in the province).

- Irregularities or sudden spikes in cases can interfere with the predictions of a single model. The "ensemble" approach of random forest means that noise and outliers are effectively mitigated, important when dealing with COVID-19 data.

- Random forest is highly scalable; it can handle large data sets efficiently.

- Many factors interact with each other in a COVID-19 outbreak, such as lockdown measures, vaccination rates and population density. Random forest is good at detecting complex interactions between features; in addition, these features do not need to be explicitly specified in the model.

In short, the random forest model is flexible, robust and scalable, three critical features which make it an excellent choice in modelling and predicting the progression of a COVID-19 outbreak. In reality, no one statistical model is used in describing and predicting an outbreak of the disease; there are too many complex dynamics and factors to be considered. Despite this, the random forest model has proven itself adept at describing and predicting the progression of COVID-19 in Newfoundland and Labrador.

# References

<sup>1</sup> - OpenAI. (2025). ChatGPT (January 17 version) [Large language model]. https://chat.openai.com/chat