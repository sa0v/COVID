---
title: "COVID-19 in Newfoundland and Labrador"
subtitle: "Analysis and Modelling"
author: "John W"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
---

# Introduction

This [RStudio](https://global.rstudio.com/categories/rstudio-ide/) notebook studies a number of data sets published by **Health Canada** on COVID-19 cases, vaccinations and variants. They will be used in this case to study the progression of the disease in Newfoundland and Labrador.

# What are the most common strains of COVID-19 currently circulating within the province?

To answer this question, we can make use of a data set which tracks the proportion of variants of COVID-19 in the province. It is updated weekly as of writing this notebook.

```{r}
library(tidyverse)
library(janitor)
library(viridis)

# Read the data
variants_df <- read_csv("https://health-infobase.canada.ca/src/data/covidLive/covid19-epiSummary-variants.csv")

# Clean the data and calculate days and proportions
variants_df <- variants_df %>%
  janitor::clean_names() %>%
  mutate(days = as.integer(as.Date(week_of_collection, format = "%Y-%m-%d") - min(as.Date(week_of_collection, format = "%Y-%m-%d")))) %>%
  mutate(variant = as.factor(variant)) %>%
  # Calculate proportions and median proportions for each variant
  group_by(variant) %>%
  mutate(proportions = proportions / 100) %>%
  mutate(median_proportion = median(proportions, na.rm = TRUE)) %>%
  ungroup()

# Reorder 'variant' based on median_proportion in descending order
variants_df$variant <- factor(variants_df$variant, levels = variants_df %>% 
                      group_by(variant) %>% 
                      summarise(median = median(median_proportion, na.rm = TRUE)) %>% 
                      arrange(desc(median)) %>% 
                      pull(variant))

# Plotting the boxplots sorted by median proportions
ggplot(variants_df, aes(x = variant, y = proportions, group = variant, color = variant)) +
  geom_boxplot() + 
  labs(
    title = "Proportion of Different COVID-19 Variants Over Time",
    subtitle = glue::glue("Newfoundland and Labrador (Last Updated on {max(variants_df$week_of_collection)})"),
    x = "COVID-19 Variant",
    y = "Proportion of Variants",
    fill = "COVID-19 Variant"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom"
  ) +
  scale_color_viridis_d() +
  scale_y_continuous(labels = scales::percent)

```

There are at least 13 known strains of COVID-19 circulating in the province. The most common strain of the disease currently circulating is on the left, the rest have been arranged in descending order according to their median proportion. Outliers indicate sudden surges or other anomalies in case numbers for a given strain. The KP.3.1.1 strain has seen the greatest variation in its case numbers, at one point accounting for between 20% and 50% of the total cases.

# What are the most commonly administered vaccines in the province?

```{r}
vaccine_df <- read.csv("https://health-infobase.canada.ca/src/data/covidLive/vaccination-administration-bydosenumber_grouped.csv")

# Boxplot for vaccine groups ordered by maximum value with wrapped x labels
vaccine_df %>%
  janitor::clean_names() %>%
  filter(prename == "Newfoundland and Labrador") %>%
  filter(vaccine_group != "Total"  & vaccine_group != "Unknown") |>
  mutate(
    vaccine_group = factor(vaccine_group, 
                           levels = vaccine_df %>%
                             filter(prename == "Newfoundland and Labrador") %>%
                             group_by(vaccine_group) %>%
                             summarise(max_doses = max(numtotal_totaldoses_admin, na.rm = TRUE)) %>%
                             arrange(desc(max_doses)) %>%
                             pull(vaccine_group)),
    wrapped_vaccine_group = str_wrap(vaccine_group, width = 50)  # Wrap the text for x labels
  ) %>%
  ggplot(aes(x = wrapped_vaccine_group, y = numtotal_totaldoses_admin, color = vaccine_group)) +
  geom_boxplot() +
  labs(
    title = str_wrap("Total Doses Administered by Vaccine Group", width = 50),
    subtitle = glue::glue("Newfoundland and Labrador (Last Updated on {max(variants_df$week_of_collection)})"),
    x = "Vaccine Group",
    y = "Total Doses Administered"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),  # Adjusting angle for right-side up labels
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust=0.5),
  ) +
  scale_fill_viridis_d() +
  scale_y_continuous(labels = scales::number) +
  scale_color_viridis_d()




```

The Pfizer-BioNTech Comirnaty vaccines (with the original strain) have been administered in the province in the largest numbers.

# Random Forest Model

To study the progression of COVID-19 in the province, we will make use of the **random forest model.** The random forest model is an "ensemble machine learning algorithm that combines multiple decision trees to improve the accuracy, robustness, and generalization of predictions. It is widely used for both regression and classification tasks and is particularly effective for handling large, complex datasets with a variety of input features."<sup>1</sup>

## Fitted Curve

```{r}
# Load necessary libraries
library(tidyverse)
library(randomForest)
library(caret)
library(ggthemes)
library(RColorBrewer)

# Load and prepare the data
data <- read.csv("https://health-infobase.canada.ca/src/data/covidLive/covid19-download.csv")

df <- data |>
  filter(prname == "Newfoundland and Labrador") |>
  mutate(
    totalcases = as.numeric(totalcases), 
    days = as.integer(as.Date(date, format = "%Y-%m-%d") - min(as.Date(date, format = "%Y-%m-%d"))),  # Calculate days since the first case
    sqrt_totalcases = sqrt(totalcases)  # Square root transformation of the totalcases
  ) |>
  drop_na(sqrt_totalcases) |> # Drop NA values for the transformed variable
  filter(!is.na(totalcases) & !is.infinite(totalcases)) |>
  filter(totalcases > 0)

# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(df$sqrt_totalcases, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

# Train a Random Forest model on the full training data
rf_model_full <- randomForest(sqrt_totalcases ~ days, data = train_data, ntree = 50)

# Predict on the full data
df$fitted_sqrt_cases_rf <- predict(rf_model_full, newdata = df)
df$fitted_cases_rf <- df$fitted_sqrt_cases_rf^2  # Convert from sqrt back to total cases

# Generate future predictions for the next 365 days
future_days <- 365  # Number of days to predict ahead
last_day <- max(df$days)  # Last observed day in the dataset
future_dates <- data.frame(days = (last_day + 1):(last_day + future_days))  # Create future days

future_sqrt_cases_rf <- predict(rf_model_full, newdata = future_dates)
future_cases_rf <- future_sqrt_cases_rf^2  # Convert from sqrt back to total cases (square of sqrt)

# Create a data frame for future predictions
future_df_rf <- data.frame(days = future_dates$days, predicted_cases = future_cases_rf)

# Combine the future predictions with the actual historical data for plotting
df_combined_rf <- bind_rows(
  df %>% mutate(predicted_cases = fitted_cases_rf, is_future = FALSE),  # Historical data with fitted values
  future_df_rf %>% mutate(totalcases = predicted_cases, is_future = TRUE)  # Future predictions with predicted cases
)

# Calculate performance metrics for training and testing data
train_preds <- predict(rf_model_full, newdata = train_data)
test_preds <- predict(rf_model_full, newdata = test_data)

# RMSE
train_rmse <- sqrt(mean((train_data$sqrt_totalcases - train_preds)^2))
test_rmse <- sqrt(mean((test_data$sqrt_totalcases - test_preds)^2))

# MAE
train_mae <- mean(abs(train_data$sqrt_totalcases - train_preds))
test_mae <- mean(abs(test_data$sqrt_totalcases - test_preds))

# R²
train_r2 <- 1 - sum((train_data$sqrt_totalcases - train_preds)^2) / sum((train_data$sqrt_totalcases - mean(train_data$sqrt_totalcases))^2)
test_r2 <- 1 - sum((test_data$sqrt_totalcases - test_preds)^2) / sum((test_data$sqrt_totalcases - mean(test_data$sqrt_totalcases))^2)

# Cross-validation metrics (using 5-fold cross-validation)
cv_results <- train(sqrt_totalcases ~ days, data = train_data, method = "rf", trControl = trainControl(method = "cv", number = 5))

cv_rmse <- cv_results$results$RMSE
cv_r2 <- cv_results$results$Rsquared
cv_mae <- cv_results$results$MAE

# Create the performance metrics text
performance_text <- paste(
  "Train RMSE: ", round(train_rmse, 2), "\n",
  "Test RMSE: ", round(test_rmse, 2), "\n",
  "Train MAE: ", round(train_mae, 2), "\n",
  "Test MAE: ", round(test_mae, 2), "\n",
  "Train R²: ", round(train_r2, 2), "\n",
  "Test R²: ", round(test_r2, 2), "\n",
  "CV RMSE: ", round(mean(cv_rmse), 2), "\n",
  "CV R²: ", round(mean(cv_r2), 2), "\n",
  "CV MAE: ", round(mean(cv_mae), 2)
)

# Plot the COVID-19 Growth Fitted and Predicted with Random Forest
ggplot(df_combined_rf, aes(x = days, y = totalcases)) +
  geom_point(data = df_combined_rf %>% filter(is_future == FALSE), color = brewer.pal(3, "Dark2")[1], size = 3) +  # Historical data points
  geom_line(data = df_combined_rf %>% filter(is_future == FALSE), aes(x = days, y = predicted_cases), color = brewer.pal(3, "Dark2")[2], linewidth = 1) +  # Fitted curve for historical data
  geom_point(data = df_combined_rf %>% filter(is_future == TRUE), color = brewer.pal(3, "Set2")[3], size = 3) +  # Future data points in different color
  geom_line(data = df_combined_rf %>% filter(is_future == TRUE), aes(x = days, y = predicted_cases), color = brewer.pal(3, "Set2")[3], linetype = "dotted", linewidth = 1) +  # Future predictions in dashed line
  labs(
    title = "COVID-19 Growth Fitted and Predicted with Random Forest Model",
    subtitle = paste("Predictions for the Next", future_days, "Days in Blue"),
    x = "Days Since First Case",
    y = "Total Cases"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),  # Center the title
    plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
  ) +
  annotate(
    "text", 
    x = max(df_combined_rf$days) - 10, 
    y = max(df_combined_rf$totalcases) * 0.30, 
    label = performance_text, 
    hjust = 1, 
    size = 4, 
    color = "black", 
  )



```

From a quick visual inspection, the fit of the curve to total cases of COVID-19 in the province is nearly ideal. This is backed up by a high $R^2$ value, very close to 1, indicating that the model is an excellent fit for the data. The root mean squared error (RMSE) is relatively low when considered against the scale of total case counts; similarly the mean average error (MAE) is also low.

With respect to cross validation, CV $R^2$ is close to 1, indicating that the model performs well across different folds. The CV RMSE is considerably higher than the overall RMSE however, indicating that the model might suffer from uneven performance across different subsets of the data. Similarly the CV MAE is also higher than the overall MAE, indicating that the model is more accurate on the full data set than on different subsets of it.

The blue region, after the 1600 day mark, indicates where the model has predicted the total number of cases for the next 365 days. This demonstrates the model's ability to provide future forecasting based on little more than a total daily case count. The model predicts a "plateau" for the total case count, beyond which the number of cases will not grow. In truth there would continue to be new reported cases of COVID-19 (as long as the disease is still circulating), so this plateau would not be perfectly flat, but the general trend is followed; case numbers are beginning to stabilize.

```{r}
# Generate learning curves by training on subsets of the data
train_sizes <- seq(1, nrow(train_data), by = 5)  # Use training sizes from 1 to full training set size
train_rmse_curve <- numeric(length(train_sizes))
test_rmse_curve <- numeric(length(train_sizes))

# Generate learning curves by training on subsets of the data
for (i in seq_along(train_sizes)) {
  subset_train_data <- train_data[1:train_sizes[i], ]
  
  # Fit Random Forest on the subset of training data
  rf_model <- randomForest(sqrt_totalcases ~ days, data = subset_train_data, ntree = 50)
  
  # Predict on training and testing data
  train_preds <- predict(rf_model, newdata = subset_train_data)
  test_preds <- predict(rf_model, newdata = test_data)
  
  # Calculate RMSE for training and testing data
  train_rmse_curve[i] <- sqrt(mean((subset_train_data$sqrt_totalcases - train_preds)^2))
  test_rmse_curve[i] <- sqrt(mean((test_data$sqrt_totalcases - test_preds)^2))
}

# Create a data frame for learning curve data
learning_curve_data <- data.frame(
  Train_Size = rep(train_sizes, each = 2),
  RMSE = c(train_rmse_curve, test_rmse_curve),
  Data = rep(c("Training", "Testing"), times = length(train_sizes))
)

# Plot the learning curves as lines
ggplot(learning_curve_data, aes(x = Train_Size, y = RMSE, color = Data)) +
  geom_line(size = 1) +  # Line for learning curves
  geom_point(size = 2) +  # Points for each RMSE value
  labs(
    title = "Learning Curves: RMSE for Training and Testing Data",
    x = "Training Set Size",
    y = "RMSE",
    color="Legend"
  ) +
  theme_minimal() +
  theme(legend.position = "right")

```
  
As a residuals plot is not as useful in evaluating the performance of a decision-tree based model like the random forest model, we have instead generated a learning curves plot. The plot shows that at around the 100 mark the training and test RMSE are at their highest point, but they very rapidly decrease, almost in unison, converging near the zero line. In summary, the model rapidly improves and generalizes well with more training data.

# Conclusion

We have provided a general picture of the number of cases of different variants of COVID-19 in Newfoundland and Labrador, Canada. We have also examined the number and commercial name of vaccines distributed in the province. Finally, we have evaluated the effectiveness of the random forest model in its ability to describe and predict the progression of the disease in the province. The random forest model provides an excellent basis on which this progression can be described and predicted. Its strengths in modelling outbreaks of the disease may be summarized as follows:

- COVID-19 data often exhibits complex, non-linear relationships between variables. The random forest model is able to handle this complexity through its use of a collection of decision trees.

- COVID-19 data is often large and complex in its own right, particularly when factors like geography, testing rates and vaccination are taken into consideration. The random forest model is particularly well suited to such data sets, as it "can handle high-dimensional data with many predictors and complex interactions."<sup>1</sup>

- Random forest makes use of multiple decision trees using different subsets of the data, averaging their predictions. This helps to generalize the model and avoid the problem of overfitting.

- Random forest has a built-in method for evaluating feature importance. This is critical in the analysis of COVID-19, as it allows for one to identify which variables (e.g. government interventions, vaccinations) are most important in predicting the outcomes (in this case, total case count).

- COVID-19 data is often less than ideal in form, containing missing values due to incomplete reporting or other factors. Random forest is, by nature, less sensitive to this issue. It makes use of "surrogate splits in decision trees when data for a particular feature is unavailable."<sup>1</sup>

- Random forest is capable of handling both continuous and categorical variables. This is useful as COVID-19 data can often contain a variety of features, both categorical and continuous. Random forest can handle both of these types without any additional pre-processing.

- Random forest is particularly good at making predictions based on historical data. It can make future predictions based on such data, critical for intervention and planning strategies. In addition, it is capable of capturing the sudden shift in trends that can often occur in an outbreak of the disease (e.g. the arrival of a new variant in the province).

- Irregularities or sudden spikes in cases can interfere with the predictions of a single model. The "ensemble" approach of random forest means that noise and outliers are effectively mitigated, important when dealing with COVID-19 data.

- Random forest is highly scalable; it can handle large data sets efficiently.

- Many factors interact with each other in a COVID-19 outbreak, such as lockdown measures, vaccination rates and population density. Random forest is good at detecting complex interactions between features; in addition, these features do not need to be explicitly specified in the model.

In short, the random forest model is flexible, robust and scalable, three critical features which make it an excellent choice in modelling and predicting the progression of a COVID-19 outbreak. In reality, no one statistical model is used in describing and predicting an outbreak of the disease; there are too many complex dynamics and factors to be considered. Despite this, the random forest model has proven itself adept at describing and predicting the progression of COVID-19 in Newfoundland and Labrador.

# References

<sup>1</sup> - OpenAI. (2025). ChatGPT (January 16 version) [Large language model]. https://chat.openai.com/chat